{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-10 16:15:32.849619: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-07-10 16:15:32.852709: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-07-10 16:15:32.903208: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-07-10 16:15:32.905920: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-07-10 16:15:33.956561: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "11490434/11490434 [==============================] - 2s 0us/step\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 26, 26, 32)        320       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2  (None, 13, 13, 32)        0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 11, 11, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPoolin  (None, 5, 5, 64)          0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 1600)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               204928    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10)                1290      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 225034 (879.04 KB)\n",
      "Trainable params: 225034 (879.04 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "## MNIST with Keras\n",
    "## 텐서플로우를 부품으로 사용하는 keras는 보다 높은 레벨로 기술할 수 있다.\n",
    "\n",
    "from keras.datasets import mnist\n",
    "\n",
    "## 손으로 쓴 숫자의 농담 화상 데이터이다.\n",
    "## 28x28 픽셀의 60000개의 훈련 데이터와 10000개의 테스트 데이터로 구성되어 있다.\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "## 데이터 가공\n",
    "## 우선, 입력을 일반적인 화상인식 CNN의 표준으로 변환한다\n",
    "## 통상의 화상인식은 컬러 화상을 대상으로 하여 1장의 화상은 세로화소수 x 가로화소수 x 색의 수: 총 3차원 텐서로 구성된다.\n",
    "## 입력 데이터 전체는 제일 앞에 화상의 매수를 추가한 4차원 텐서로 구성된다.\n",
    "\n",
    "## 주어진 데이터는 흑백이미지로, 화상의 매수 x 세로화소수 x 가로화소수로 나타나서 색의 수 1을 하나의 차원로 더하여 4차원 텐서로 변환한다.\n",
    "\n",
    "img_rows, img_cols = 28, 28\n",
    "\n",
    "X_train = X_train.reshape(X_train.shape[0], img_rows, img_cols, 1) ## 60000 x 28 x 28 x 1\n",
    "X_test = X_test.reshape(X_test.shape[0], img_rows, img_cols, 1) ## 10000 x 28 x 28 x 1\n",
    "input_shape = (img_rows, img_cols, 1)\n",
    "\n",
    "X_train = X_train.astype('float32')/255     ## 32비트 부동소수점으로 변환하고 255로 나누어 0~1 사이의 값으로 정규화한다.\n",
    "X_test = X_test.astype('float32')/255\n",
    "\n",
    "## 레이블을 원-핫 인코딩으로 변환한다.\n",
    "## 원-핫 인코딩이란, 0~9까지의 정수형 레이블을 10개의 요소를 가진 벡터로 변환하는 것이다.\n",
    "## 예를 들어, 0은 [1, 0, 0, 0, 0, 0, 0, 0, 0, 0]으로 변환된다.\n",
    "## 이는 0부터 9까지의 정수형 레이블을 가진 데이터를 10개의 클래스를 가진 분류 문제로 변환하는 것이다.\n",
    "\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "Y_train = to_categorical(y_train)\n",
    "Y_test = to_categorical(y_test)\n",
    "\n",
    "## 모델 구축\n",
    "## keras는 Sequential 모델을 사용하여 모델을 구축한다.\n",
    "## Sequential 모델은 레이어를 선형으로 쌓아 구축하는 모델이다.\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Dense, Flatten\n",
    "\n",
    "n_out = len(Y_train[0]) ## 10\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=input_shape)) ## 32개의 필터를 사용하여 3x3의 커널을 적용한다.\n",
    "model.add(MaxPooling2D(pool_size=(2, 2))) ## 2x2의 맥스 풀링을 적용한다.\n",
    "model.add(Conv2D(64, kernel_size=(3, 3), activation='relu')) ## 64개의 필터를 사용하여 3x3의 커널을 적용한다.\n",
    "model.add(MaxPooling2D(pool_size=(2, 2))) ## 2x2의 맥스 풀링을 적용한다.\n",
    "model.add(Flatten()) ## 1차원으로 변환한다.\n",
    "model.add(Dense(128, activation='relu')) ## 128개의 노드를 가진 완전연결층을 적용한다.\n",
    "model.add(Dense(n_out, activation='softmax')) ## 10개의 노드를 가진 완전연결층을 적용한다.\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "300/300 [==============================] - 10s 31ms/step - loss: 0.2490 - accuracy: 0.9244\n",
      "Epoch 2/5\n",
      "300/300 [==============================] - 9s 29ms/step - loss: 0.0613 - accuracy: 0.9813\n",
      "Epoch 3/5\n",
      "300/300 [==============================] - 9s 28ms/step - loss: 0.0405 - accuracy: 0.9872\n",
      "Epoch 4/5\n",
      "300/300 [==============================] - 9s 29ms/step - loss: 0.0303 - accuracy: 0.9907\n",
      "Epoch 5/5\n",
      "300/300 [==============================] - 9s 29ms/step - loss: 0.0230 - accuracy: 0.9926\n",
      "Test loss:  0.036492105573415756\n",
      "Test accuracy:  0.9882000088691711\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
    "model.fit(X_train, Y_train, epochs=5, batch_size=200)\n",
    "score = model.evaluate(X_test, Y_test, verbose=0)\n",
    "print('Test loss: ', score[0])\n",
    "print('Test accuracy: ', score[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
